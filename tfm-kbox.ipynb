{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## TFM: CLUSTERIZATION ALGORITHMS","metadata":{}},{"cell_type":"code","source":"#Installs\n!pip install xlrd\n!pip install openpyxl\n!pip install geneticalgorithm\n!pip install pyeasyga","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T11:33:10.891166Z","iopub.execute_input":"2021-07-08T11:33:10.892006Z","iopub.status.idle":"2021-07-08T11:33:48.433052Z","shell.execute_reply.started":"2021-07-08T11:33:10.891844Z","shell.execute_reply":"2021-07-08T11:33:48.431505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Imports\nimport numpy as np\nimport pandas as pd \nimport math\n#from datetime import datetime\n#from contextlib import redirect_stdout #For the log files\n\nimport random\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nrc(\"text\", usetex=False)\n\n\n%matplotlib inline\nimport seaborn as sns\n\n##Kmeans\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n##GMM\nfrom sklearn.mixture import GaussianMixture\n\n##DBSCAN\nfrom sklearn.cluster import DBSCAN\n\n##OPTICS\nfrom sklearn.cluster import OPTICS\nfrom sklearn.datasets import make_blobs\n\n##Mean-Shift\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\n\n##GA\nfrom pyeasyga import pyeasyga\nfrom scipy.stats import norm\n\n##Likelihood \nfrom scipy.stats import norm\nimport scipy.stats as stats\nimport copy\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:33:48.435704Z","iopub.execute_input":"2021-07-08T11:33:48.43628Z","iopub.status.idle":"2021-07-08T11:33:50.08093Z","shell.execute_reply.started":"2021-07-08T11:33:48.436213Z","shell.execute_reply":"2021-07-08T11:33:50.079492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = \"../input/tfm-data/KBOXSales-DataTestCTES-25032021 2.xlsx\"\ndf = pd.read_excel(file_name, engine='openpyxl', sheet_name='KMMVPRBQvm')\ndf.drop(['Unnamed: 92', 'Unnamed: 93',\t'Unnamed: 94',\t'Unnamed: 95',\t'Unnamed: 96', \n         'Unnamed: 97',\t'Unnamed: 98',\t'Unnamed: 99'], axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:33:50.083495Z","iopub.execute_input":"2021-07-08T11:33:50.083987Z","iopub.status.idle":"2021-07-08T11:37:40.910892Z","shell.execute_reply.started":"2021-07-08T11:33:50.083935Z","shell.execute_reply":"2021-07-08T11:37:40.909154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_s = df[:5495].copy() \ndf_s.head()\n#df.head() #5497","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:37:40.913716Z","iopub.execute_input":"2021-07-08T11:37:40.914254Z","iopub.status.idle":"2021-07-08T11:37:40.975306Z","shell.execute_reply.started":"2021-07-08T11:37:40.914196Z","shell.execute_reply":"2021-07-08T11:37:40.973974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n              'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n              'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20']].copy()\n\ntrain.dropna(axis=0, inplace=True)\ntrain.reset_index(drop = True, inplace=True)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:37:40.977126Z","iopub.execute_input":"2021-07-08T11:37:40.977492Z","iopub.status.idle":"2021-07-08T11:37:41.070485Z","shell.execute_reply.started":"2021-07-08T11:37:40.977458Z","shell.execute_reply":"2021-07-08T11:37:41.069058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trains_cols = ['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', '%ContVta19', 'CtVta19', \n#'%ContMBto19', 'CtMBto19', 'EvoVta19', '%Dto19', '%DifDto19']\n#test_cols = ['Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', \n#'Key-WCI20', 'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T06:48:21.802386Z","iopub.execute_input":"2021-07-08T06:48:21.802835Z","iopub.status.idle":"2021-07-08T06:48:21.80744Z","shell.execute_reply.started":"2021-07-08T06:48:21.802788Z","shell.execute_reply":"2021-07-08T06:48:21.806123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\ny = train['Key-P20'].copy()\n\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(y)\ny = labelEncoder.transform(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:58:05.778938Z","iopub.execute_input":"2021-07-08T11:58:05.779335Z","iopub.status.idle":"2021-07-08T11:58:05.791064Z","shell.execute_reply.started":"2021-07-08T11:58:05.779299Z","shell.execute_reply":"2021-07-08T11:58:05.789567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0) Plots\n\n### 0.1) Short codes, and key plots","metadata":{}},{"cell_type":"code","source":"X_plot = train[['CodigoCLI', 'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20', 'KHR20', \n                'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:14:35.330256Z","iopub.execute_input":"2021-07-07T20:14:35.330612Z","iopub.status.idle":"2021-07-07T20:14:35.336377Z","shell.execute_reply.started":"2021-07-07T20:14:35.33058Z","shell.execute_reply":"2021-07-07T20:14:35.335642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in X_plot:\n#    if i == 'CodigoCLI':\n#        continue\n#    else:\n#        plt.figure(figsize=(10,7))\n#        sns.swarmplot(x=i, y=X_plot.index, data=X_plot, dodge=True, palette='viridis')\n#        #sns.violinplot(x='Key-P20', y=X_plot.index, data=X_plot, split='True', palette='rainbow')\n#        plt.title(\"Cluster distribution\")","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:14:40.247645Z","iopub.execute_input":"2021-07-07T20:14:40.248192Z","iopub.status.idle":"2021-07-07T20:14:40.252381Z","shell.execute_reply.started":"2021-07-07T20:14:40.248154Z","shell.execute_reply":"2021-07-07T20:14:40.251456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in X_plot:\n#    if i == 'CodigoCLI':\n#        continue\n#    else:\n#        plt.figure(figsize=(12,8))\n#        sns.stripplot(x='Key-P20', y=X_plot.index, data=X_plot, jitter=True, dodge=True, palette='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.067043Z","iopub.status.idle":"2021-07-06T08:34:50.067446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X_plot.iloc[:,0], X_plot.iloc[:,1]) #  X.iloc[:,2],  X.iloc[:,3]\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Data Distribution')\nplt.show()\n#X.drop('CodigoCLI', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:15:08.944826Z","iopub.execute_input":"2021-07-07T20:15:08.945207Z","iopub.status.idle":"2021-07-07T20:15:16.945831Z","shell.execute_reply.started":"2021-07-07T20:15:08.945175Z","shell.execute_reply":"2021-07-07T20:15:16.943089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.2) Indexes Plots\n\nAlways (y,x)\n\nGeneral (Value)\n- Key-WCI - WCI/Ct2VM\n- Key-R20 - WPI/IRP-Cli20base1\n\nSales\n\n- Key-V20 - WSEI/IPEV20\n- Key-P20 - SCI/CtVta20\n\nProfit\n- Key-R20 - WPI/IRP-Cli20base1\n- Key-B20 - GMCI/CtMbto20\n\nQuality\n- Key-QV20 - TPI/IRT-Cli20Base1\n- Key-QM20 - API/IRM-Cli20base1\n\n--\n- WCI = Ct2VM\n- WPI = IRP-Clibase1\n- WSEI = IPEV\n- SCI = CtVta\n- GMCI = CtMbto\n- TPI = IRT-Clibase1\n- API = IRM-Clibase1","metadata":{}},{"cell_type":"code","source":"df_s.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.069757Z","iopub.status.idle":"2021-07-06T08:34:50.070168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_plot_pt1 = df_s[['Ct2VM20', 'Ct2VM', \n               'IRP-Cli20', #'evolIRP-Cli20',\n               'IPEV20', 'CtVta20',\n               'CtMBto19', 'CtMBto20', \n               'IRT-Cli20', #'evolIRT-Cli20', \n               'IRM-Cli20',]].copy() #'evolIRM-Cli20',\n\nX_plot_pt2 = df_s[['IRP-Cli20base1',  'IRP-Cli20base1',  'IRP-Cli20base1']].copy()\n\nX_plot_pt1.dropna(axis=0, inplace=True)\nX_plot_pt2.dropna(axis=0, inplace=True)\n\nX_plot_pt1.reset_index(drop = True, inplace=True)\nX_plot_pt2.reset_index(drop = True, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.071147Z","iopub.status.idle":"2021-07-06T08:34:50.071552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\nX_plot_pt1[['Ct2VM20', 'Ct2VM', \n        'IRP-Cli20', #'evolIRP-Cli20',\n        'IPEV20', 'CtVta20',\n        'CtMBto19', 'CtMBto20', \n        'IRT-Cli20', #'evolIRT-Cli20', \n        'IRM-Cli20',]] = scaler.fit_transform(X_plot_pt1)\n\nX_plot_pt1","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.07254Z","iopub.status.idle":"2021-07-06T08:34:50.072978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.2) Indexes Plots\n\nAlways (y,x)\n\nGeneral (Value)\n- Key-WCI - WCI/Ct2VM\n- Key-R20 - WPI/IRP-Cli20base1\n\nSales\n\n- Key-V20 - WSEI/IPEV20\n- Key-P20 - SCI/CtVta20\n\nProfit\n- Key-R20 - WPI/IRP-Cli20base1\n- Key-B20 - GMCI/CtMbto20\n\nQuality\n- Key-QV20 - TPI/IRT-Cli20Base1\n- Key-QM20 - API/IRM-Cli20base1\n\n--\n- WCI = Ct2VM\n- WPI = IRP-Clibase1\n- WSEI = IPEV\n- SCI = CtVta\n- GMCI = CtMbto\n- TPI = IRT-Clibase1\n- API = IRM-Clibase1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:18:20.372357Z","iopub.execute_input":"2021-06-02T08:18:20.373167Z","iopub.status.idle":"2021-06-02T08:18:20.381137Z","shell.execute_reply.started":"2021-06-02T08:18:20.373127Z","shell.execute_reply":"2021-06-02T08:18:20.38012Z"}}},{"cell_type":"code","source":"# Generate scatter plot\nfor i in range(len(X_plot_pt1.columns)):\n    #colors = list(map(lambda x: '#3b4cc0' if x == 1 else '#b40426', labels))\n    plt.scatter(X_plot_pt1.index.values, X_plot_pt1.iloc[:,i], marker=\"o\", picker=True)\n    plt.title(f'Indicators clustering')\n    plt.ylabel('Axis {}'.format(X_plot_pt1.iloc[:,i].name))\n    plt.xlabel('Indices')\n    plt.figtext(0.5, 0, \"Avg:{}\".format((X_plot_pt1.iloc[:,i]).mean()), ha=\"center\", fontsize=7, bbox={\"facecolor\":\"white\", \"alpha\":0.5, \"pad\":5})\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.073859Z","iopub.status.idle":"2021-07-06T08:34:50.074254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate scatter plot\nfor i in range(len(X_plot_pt2.columns)):\n    #colors = list(map(lambda x: '#3b4cc0' if x == 1 else '#b40426', labels))\n    plt.scatter(X_plot_pt2.index.values, X_plot_pt2.iloc[:,i], marker=\"o\", picker=True)\n    plt.title(f'Indicators clustering')\n    plt.xlabel('Axis {}'.format(X_plot_pt2.iloc[:,i].name))\n    plt.ylabel('Indices')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.075025Z","iopub.status.idle":"2021-07-06T08:34:50.075425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1) Based on Partition\n### 1.1) Kmeans","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X.iloc[:,0], X.iloc[:,1]) #  X.iloc[:,2],  X.iloc[:,3]\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Data Distribution')\nplt.show()\n#X.drop('CodigoCLI', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:12:05.960147Z","iopub.execute_input":"2021-07-07T20:12:05.960532Z","iopub.status.idle":"2021-07-07T20:12:06.076902Z","shell.execute_reply.started":"2021-07-07T20:12:05.960496Z","shell.execute_reply":"2021-07-07T20:12:06.075648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\n\n#predictions from kmeans\npred = kmeans.predict(X)\nframe = pd.DataFrame(X)\nframe['cluster'] = pred\n#frame.columns = ['Weight', 'Height', 'cluster']","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.077692Z","iopub.status.idle":"2021-07-06T08:34:50.078132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frame","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.07903Z","iopub.status.idle":"2021-07-06T08:34:50.079431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting results\ncolor=['blue','green','cyan', 'black']\nfor k in range(0,4):\n    X = frame[frame[\"cluster\"]==k]\n    #plt.scatter(X[\"Weight\"],X[\"Height\"],c=color[k])\n    plt.scatter(X.iloc[:,0], X.iloc[:,1], c=color[k])\n    plt.scatter(X.iloc[:,2], X.iloc[:,3], c=color[k])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:14:10.133695Z","iopub.execute_input":"2021-07-07T20:14:10.134099Z","iopub.status.idle":"2021-07-07T20:14:10.153725Z","shell.execute_reply.started":"2021-07-07T20:14:10.134063Z","shell.execute_reply":"2021-07-07T20:14:10.152068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=4, init='random',tol=1e-04, random_state=0, algorithm = 'auto') \nkmeans.fit(X)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.081849Z","iopub.status.idle":"2021-07-06T08:34:50.082386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate distortion for a range of number of cluster\n#distortions = []\n#for i in range(1, 11):\n#    km = KMeans(n_clusters=i, init='random',\n#                n_init=10, max_iter=300,\n#                tol=1e-04, random_state=0 )\n#    km.fit(X)\n#    distortions.append(km.inertia_)\n#\n## plot\n#plt.plot(range(1, 11), distortions, marker='o')\n#plt.xlabel('Number of clusters')\n#plt.ylabel('Distortion')\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.083433Z","iopub.status.idle":"2021-07-06T08:34:50.083883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.084642Z","iopub.status.idle":"2021-07-06T08:34:50.08505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X)):\n        predict_me = np.array(X[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n    print(correct/len(X))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.086252Z","iopub.status.idle":"2021-07-06T08:34:50.086893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\nkmeans.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.087877Z","iopub.status.idle":"2021-07-06T08:34:50.088282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X)):\n        predict_me = np.array(X[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n\n    print(correct/len(X))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.089377Z","iopub.status.idle":"2021-07-06T08:34:50.089854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.1) Normalization, and Using less data / Using KBOX data\n\nIn this section we will first try and use less data, then we will use more initial data from Kbox","metadata":{}},{"cell_type":"code","source":"#scaler = MinMaxScaler(feature_range=(-1, 1))\n#X_norm =  scaler.fit_transform(X[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']])\n#X_norm = pd.DataFrame(X_norm, columns=['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.090882Z","iopub.status.idle":"2021-07-06T08:34:50.091314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For general matrix WCI/IPoC, WPI/IRPo\n##WCI - Vta19 y MBto19\n##WPI - VtaTar19, VtaCos19, Rappel19\n\n#X = train[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.092262Z","iopub.status.idle":"2021-07-06T08:34:50.092666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = train[['Vta19', 'MBto19']].copy()  #WCI\nX = train[['VtaTar19', 'VtaCos19', 'Rappel19']].copy() # WPI\ny = train['Key-P20'].copy()\n\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(y)\ny = labelEncoder.transform(y)\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.093603Z","iopub.status.idle":"2021-07-06T08:34:50.094034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=4, init='random',tol=1e-04, random_state=0, algorithm = 'auto') \nkmeans.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.094979Z","iopub.status.idle":"2021-07-06T08:34:50.09538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled = np.array(X_scaled)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.096342Z","iopub.status.idle":"2021-07-06T08:34:50.096821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n\n    print(correct/len(X))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.097732Z","iopub.status.idle":"2021-07-06T08:34:50.098157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For sales matrix WSEI/IPEV, SCI/ICV\n#WSEI- Vta19, 'MBto19'\n#SCI - Vta19\n\nX = train[['Vta19', 'MBto19']].copy()\ny = train['Key-P20'].copy()\n\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(y)\ny = labelEncoder.transform(y)\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n\nkmeans = KMeans(n_clusters=4, init='random',tol=1e-04, random_state=0, algorithm = 'auto') \nkmeans.fit(X_scaled)\n\nX_scaled = np.array(X_scaled)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.099171Z","iopub.status.idle":"2021-07-06T08:34:50.099575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n\n    print(correct/len(X))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.100618Z","iopub.status.idle":"2021-07-06T08:34:50.101097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For profit matrix WPI/IRP, GMCI/ICMB\n#WPI- \n#GMCI - \n\nX = train[['Vta19', 'MBto19']].copy()\ny = train['Key-P20'].copy()\n\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(y)\ny = labelEncoder.transform(y)\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n\nkmeans = KMeans(n_clusters=4, init='random',tol=1e-04, random_state=0, algorithm = 'auto') \nkmeans.fit(X_scaled)\n\nX_scaled = np.array(X_scaled)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.102083Z","iopub.status.idle":"2021-07-06T08:34:50.102485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n\n    print(correct/len(X_scaled))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.103223Z","iopub.status.idle":"2021-07-06T08:34:50.103635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train.iloc[:,6:].head(5)\n#KHR20 --  K Main Matrix\n#KVP20 --  K Sales matrix\n#KRB20 --  K Profit matrix\n#KeyQVM20 --  K Sales Quality matrix\n\n#Short-KHR20 --  Short K Main Matrix\n#Short-KVP20 --  Short K Sales matrix\n#Short-KRB20 --  Short K Profit matrix\n#Short-KeyQVM20 -- Short K Sales Quality matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.104674Z","iopub.status.idle":"2021-07-06T08:34:50.105108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.2) With KBOX data","metadata":{}},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.106032Z","iopub.status.idle":"2021-07-06T08:34:50.106421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\ny = train_x['Key-P20'].copy()\n\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(y)\ny = labelEncoder.transform(y)\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n\nkmeans = KMeans(n_clusters=4, init='random', tol=1e-04, random_state=0, algorithm = 'auto') \nkmeans.fit(X_scaled)\n\n#X_scaled = np.array(X_scaled)\n#y = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:24:08.833919Z","iopub.execute_input":"2021-07-07T20:24:08.834732Z","iopub.status.idle":"2021-07-07T20:24:08.997526Z","shell.execute_reply.started":"2021-07-07T20:24:08.834683Z","shell.execute_reply":"2021-07-07T20:24:08.99687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct_list = []\n\nfor i in range(15):\n    y = train_x.iloc[:, 18+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = kmeans.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n    correct_list.append(correct/len(X_scaled))\n    print(correct/len(X_scaled))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:24:40.376159Z","iopub.execute_input":"2021-07-07T20:24:40.376528Z","iopub.status.idle":"2021-07-07T20:24:55.730613Z","shell.execute_reply.started":"2021-07-07T20:24:40.376494Z","shell.execute_reply":"2021-07-07T20:24:55.729532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(correct_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:25:02.899574Z","iopub.execute_input":"2021-07-07T20:25:02.899996Z","iopub.status.idle":"2021-07-07T20:25:02.906978Z","shell.execute_reply.started":"2021-07-07T20:25:02.899956Z","shell.execute_reply":"2021-07-07T20:25:02.905859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculate distortion for a range of number of cluster\ndistortions = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters=i, init='random',\n                n_init=10, max_iter=300,\n                tol=1e-04, random_state=0 )\n    km.fit(X_scaled)\n    distortions.append(km.inertia_)\n\n# plot\nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\n#plt.show()\nplt.savefig('./elbow_plot.png', dpi=200)\nplt.clf()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T20:27:28.840457Z","iopub.execute_input":"2021-07-07T20:27:28.840867Z","iopub.status.idle":"2021-07-07T20:27:31.226722Z","shell.execute_reply.started":"2021-07-07T20:27:28.840825Z","shell.execute_reply":"2021-07-07T20:27:31.225812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Based on Distribution\n### 2.1) GMM ","metadata":{}},{"cell_type":"code","source":"# training gaussian mixture model \ngmm = GaussianMixture(n_components=5, reg_covar=1e-4)\ngmm.fit(X)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:04:22.077735Z","iopub.execute_input":"2021-07-06T15:04:22.078141Z","iopub.status.idle":"2021-07-06T15:04:22.576478Z","shell.execute_reply.started":"2021-07-06T15:04:22.078107Z","shell.execute_reply":"2021-07-06T15:04:22.575337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions from gmm\nlabels = gmm.predict(X)\nframe = pd.DataFrame(X)\nframe['cluster'] = labels\n#frame.columns = ['Weight', 'Height', 'cluster']","metadata":{"execution":{"iopub.status.busy":"2021-07-06T18:55:15.928916Z","iopub.execute_input":"2021-07-06T18:55:15.92949Z","iopub.status.idle":"2021-07-06T18:55:15.943876Z","shell.execute_reply.started":"2021-07-06T18:55:15.929441Z","shell.execute_reply":"2021-07-06T18:55:15.942499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color=['blue','green','cyan', 'black']\nfor k in range(0,4):\n    X = frame[frame[\"cluster\"]==k]\n    plt.scatter(X.iloc[:,1], X.iloc[:,2], c=color[k])\n    #plt.scatter(X.iloc[:,2], X.iloc[:,3], c=color[k])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:04:25.926507Z","iopub.execute_input":"2021-07-06T15:04:25.926938Z","iopub.status.idle":"2021-07-06T15:04:26.148358Z","shell.execute_reply.started":"2021-07-06T15:04:25.926901Z","shell.execute_reply":"2021-07-06T15:04:26.147104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\ngmm.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:04:30.317325Z","iopub.execute_input":"2021-07-06T15:04:30.317733Z","iopub.status.idle":"2021-07-06T15:04:30.677547Z","shell.execute_reply.started":"2021-07-06T15:04:30.317696Z","shell.execute_reply":"2021-07-06T15:04:30.676313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    y = train.iloc[:, 5+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = gmm.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n    print(correct/len(X_scaled))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:04:30.76045Z","iopub.execute_input":"2021-07-06T15:04:30.761246Z","iopub.status.idle":"2021-07-06T15:04:32.047034Z","shell.execute_reply.started":"2021-07-06T15:04:30.761178Z","shell.execute_reply":"2021-07-06T15:04:32.045901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.2) With KBOX data\n","metadata":{}},{"cell_type":"code","source":"mu\n\nmu_re = np.reshape(mu, (4, 17)) ","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:11:46.689927Z","iopub.execute_input":"2021-07-06T16:11:46.690485Z","iopub.status.idle":"2021-07-06T16:11:46.694033Z","shell.execute_reply.started":"2021-07-06T16:11:46.690446Z","shell.execute_reply":"2021-07-06T16:11:46.693265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\n\nX_scaled = scaler.fit_transform(X)\n\n# training gaussian mixture model \ngmm = GaussianMixture(n_components=3, reg_covar=1e-4, \n                      means_init = np.transpose(mu_means), \n                      weights_init = np.mean(pi_means, axis=0))\ngmm.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:44:15.875058Z","iopub.execute_input":"2021-07-08T07:44:15.875425Z","iopub.status.idle":"2021-07-08T07:44:16.154123Z","shell.execute_reply.started":"2021-07-08T07:44:15.875394Z","shell.execute_reply":"2021-07-08T07:44:16.15296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_init = []\ninit = []\n\nfor i in range(15):\n    y = train_x.iloc[:, 18+i].copy()\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(y)\n    y = labelEncoder.transform(y)\n    y = np.array(y)\n    \n    correct = 0\n    for i in range(len(X_scaled)):\n        predict_me = np.array(X_scaled[i])\n        predict_me = predict_me.reshape(-1, len(predict_me))\n        prediction = gmm.predict(predict_me)\n        if prediction[0] == y[i]:\n            correct += 1\n            \n    init.append(correct/len(X_scaled))\n    print(correct/len(X_scaled))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:44:19.819755Z","iopub.execute_input":"2021-07-08T07:44:19.820093Z","iopub.status.idle":"2021-07-08T07:44:28.280394Z","shell.execute_reply.started":"2021-07-08T07:44:19.820064Z","shell.execute_reply":"2021-07-08T07:44:28.27914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_clusters = len(np.unique(labels))\nno_noise = np.sum(np.array(labels) == -1, axis=0)\n\nprint('Estimated no. of clusters: %d' % no_clusters)\nprint('Estimated no. of noise points: %d' % no_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T18:55:49.109921Z","iopub.execute_input":"2021-07-06T18:55:49.110324Z","iopub.status.idle":"2021-07-06T18:55:49.117613Z","shell.execute_reply.started":"2021-07-06T18:55:49.110281Z","shell.execute_reply":"2021-07-06T18:55:49.116608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.3) Grid Search\n","metadata":{}},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n# training gaussian mixture model \ngmm = GaussianMixture(n_components=3, reg_covar=1e-4)\ngmm.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:57:23.929334Z","iopub.execute_input":"2021-07-08T11:57:23.929747Z","iopub.status.idle":"2021-07-08T11:57:24.455951Z","shell.execute_reply.started":"2021-07-08T11:57:23.929709Z","shell.execute_reply":"2021-07-08T11:57:24.454425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:06:39.38822Z","iopub.execute_input":"2021-07-06T15:06:39.388721Z","iopub.status.idle":"2021-07-06T15:06:39.404557Z","shell.execute_reply.started":"2021-07-06T15:06:39.388671Z","shell.execute_reply":"2021-07-06T15:06:39.403052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color=['blue','green','cyan', 'black']\nfor k in range(0,4):\n    X_scaled = frame[frame[\"cluster\"]==k]\n    plt.scatter(X_scaled.index.values, X_scaled.iloc[:,1],)\n    #plt.scatter(X.iloc[:,2], X.iloc[:,3], c=color[k])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:06:39.808529Z","iopub.execute_input":"2021-07-06T15:06:39.808951Z","iopub.status.idle":"2021-07-06T15:06:40.012571Z","shell.execute_reply.started":"2021-07-06T15:06:39.808916Z","shell.execute_reply":"2021-07-06T15:06:40.011755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 1\n\nfor i in range(7):\n    reg = 1e-5 #* 100 * (y+1)\n\n    for y in range(5):\n        # training gaussian mixture model \n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        X_scaled = scaler.fit_transform(X)\n        #reg = 1e-5 * 100 * (y+1)\n        gmm = GaussianMixture(n_components=i+1, reg_covar= reg)\n        gmm.fit(X_scaled)\n        \n        #predictions from gmm\n        labels = gmm.predict(X_scaled)\n        frame = pd.DataFrame(X_scaled)\n        frame['cluster'] = labels\n        \n        color=['blue','green','cyan', 'black']\n        for k in range(0,4):\n            X_scaled = frame[frame[\"cluster\"]==k]\n            plt.scatter(X_scaled.index.values, X_scaled.iloc[:,1],)\n            #plt.scatter(X.iloc[:,2], X.iloc[:,3], c=color[k])\n        # BOTTOM LABEL\n        plt.figtext(0.5, 0, \"Comps:{}, Reg_covar:{}\".format(i+1, reg), ha=\"center\", fontsize=7, bbox={\"facecolor\":\"white\", \"alpha\":0.5, \"pad\":5})\n        plt.savefig('./gmm_film{}.png'.format(num))\n        plt.clf()\n\n        #plt.show()\n        #plt.close()\n        reg = reg * 10\n        num = num + 1","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.126646Z","iopub.status.idle":"2021-07-06T08:34:50.127087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3) Based on Density\n### 3.1) DBSCAN","metadata":{}},{"cell_type":"code","source":"#db = DBSCAN(eps=epsilon, min_samples=min_samples).fit(X)\ndb = DBSCAN(eps=1, min_samples=50).fit(X)\n\nlabels = db.labels_\nnp.unique(labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:03:46.927884Z","iopub.execute_input":"2021-07-07T16:03:46.928266Z","iopub.status.idle":"2021-07-07T16:03:47.064845Z","shell.execute_reply.started":"2021-07-07T16:03:46.928228Z","shell.execute_reply":"2021-07-07T16:03:47.063682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1.2) With KBOX data\n","metadata":{}},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:03:56.428574Z","iopub.execute_input":"2021-07-07T16:03:56.429164Z","iopub.status.idle":"2021-07-07T16:03:56.456523Z","shell.execute_reply.started":"2021-07-07T16:03:56.429128Z","shell.execute_reply":"2021-07-07T16:03:56.455578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db = DBSCAN(eps=0.1, min_samples=50).fit(X_scaled)\n\nlabels = db.labels_\nnp.unique(labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.130698Z","iopub.status.idle":"2021-07-06T08:34:50.13114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_clusters = len(np.unique(labels))\nno_noise = np.sum(np.array(labels) == -1, axis=0)\n\nprint('Estimated no. of clusters: %d' % no_clusters)\nprint('Estimated no. of noise points: %d' % no_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.13207Z","iopub.status.idle":"2021-07-06T08:34:50.132468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1.3) Grid Search\n","metadata":{}},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n\ndb = DBSCAN(eps=0.1, min_samples=50).fit(X_scaled)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:12:50.312063Z","iopub.execute_input":"2021-07-07T16:12:50.31262Z","iopub.status.idle":"2021-07-07T16:12:50.540302Z","shell.execute_reply.started":"2021-07-07T16:12:50.312562Z","shell.execute_reply":"2021-07-07T16:12:50.539258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:12:55.579602Z","iopub.execute_input":"2021-07-07T16:12:55.580214Z","iopub.status.idle":"2021-07-07T16:12:55.586389Z","shell.execute_reply.started":"2021-07-07T16:12:55.580167Z","shell.execute_reply":"2021-07-07T16:12:55.585483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 1\nepsilon = 0.1\n\nfor i in range(7):\n    min_s = 50\n\n    for y in range(5):\n        # training gaussian mixture model \n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        X_scaled = scaler.fit_transform(X)\n        labels = DBSCAN(eps = epsilon, min_samples = min_s).fit_predict(X_scaled)\n        \n        #predictions from gmm\n        #labels = gmm.predict(X_scaled)\n        frame = pd.DataFrame(X_scaled)\n        frame['cluster'] = labels\n        \n        color=['blue','green','cyan', 'black']\n        for k in range(0,4):\n            X_scaled = frame[frame[\"cluster\"]==k]\n            plt.scatter(X_scaled.index.values, X_scaled.iloc[:,1],)\n            #plt.scatter(X.iloc[:,2], X.iloc[:,3], c=color[k])\n        # BOTTOM LABEL\n        plt.figtext(0.5, 0, \"Epsilon:{}, Min_samples:{}\".format(epsilon, min_s), ha=\"center\", fontsize=7, bbox={\"facecolor\":\"white\", \"alpha\":0.5, \"pad\":5})\n        #plt.savefig('./dbscan_film{}.png'.format(num))\n        #plt.show()\n\n        #plt.clf()\n        plt.show()\n        #plt.close()\n        min_s = min_s + 30\n        \n        num = num + 1\n        print(min_s)\n    epsilon = epsilon + 0.2\n    print(epsilon)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:10:24.374611Z","iopub.execute_input":"2021-07-07T16:10:24.374969Z","iopub.status.idle":"2021-07-07T16:10:40.218095Z","shell.execute_reply.started":"2021-07-07T16:10:24.374937Z","shell.execute_reply":"2021-07-07T16:10:40.21716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2) OPTICS","metadata":{}},{"cell_type":"code","source":"X = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19',]].copy() ##kbox data\n             #'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             #'%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:24.406259Z","iopub.execute_input":"2021-07-08T12:05:24.406869Z","iopub.status.idle":"2021-07-08T12:05:24.415007Z","shell.execute_reply.started":"2021-07-08T12:05:24.406815Z","shell.execute_reply":"2021-07-08T12:05:24.413683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration options\nepsilon = 2000.0\nmin_samples = 40\ncluster_method = 'xi'\nmetric = 'minkowski'\n\n# Compute OPTICS\ndb = OPTICS(max_eps=epsilon, min_samples=min_samples, cluster_method=cluster_method, metric=metric).fit(X)\nlabels = db.labels_","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:25.791997Z","iopub.execute_input":"2021-07-08T12:05:25.792417Z","iopub.status.idle":"2021-07-08T12:05:28.009996Z","shell.execute_reply.started":"2021-07-08T12:05:25.792355Z","shell.execute_reply":"2021-07-08T12:05:28.008697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab = np.unique(labels)\nlab","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:29.461295Z","iopub.execute_input":"2021-07-08T12:05:29.461913Z","iopub.status.idle":"2021-07-08T12:05:29.469297Z","shell.execute_reply.started":"2021-07-08T12:05:29.461857Z","shell.execute_reply":"2021-07-08T12:05:29.468176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_clusters = len(np.unique(labels))\nno_noise = np.sum(np.array(labels) == -1, axis=0)\n\nprint('Estimated no. of clusters: %d' % no_clusters)\nprint('Estimated no. of noise points: %d' % no_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:31.66334Z","iopub.execute_input":"2021-07-08T12:05:31.663954Z","iopub.status.idle":"2021-07-08T12:05:31.672615Z","shell.execute_reply.started":"2021-07-08T12:05:31.663894Z","shell.execute_reply":"2021-07-08T12:05:31.671438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate scatter plot for training data\ncolors = list(map(lambda x: '#3b4cc0' if x == 1 else '#b40426', labels))\nplt.scatter(X.iloc[:,0], X.iloc[:,2], c=colors, marker=\"o\", picker=True)\nplt.title(f'OPTICS clustering')\nplt.xlabel('Axis X[0]')\nplt.ylabel('Axis X[1]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:33.363641Z","iopub.execute_input":"2021-07-08T12:05:33.364233Z","iopub.status.idle":"2021-07-08T12:05:33.595284Z","shell.execute_reply.started":"2021-07-08T12:05:33.364176Z","shell.execute_reply":"2021-07-08T12:05:33.594018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate reachability plot\nreachability = db.reachability_[db.ordering_]\nplt.plot(reachability)\nplt.title('Reachability plot')\nplt.xlabel('Ordering of Points')\nplt.ylabel('Reachability Distance')\nplt.savefig('reachability.png', dpi=200)\n#plt.show()\n\n\n#ordering of the points as processed by OPTICS on the x-axis and the reachability distance on the y-axis. ","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:11:08.357652Z","iopub.execute_input":"2021-07-08T12:11:08.358106Z","iopub.status.idle":"2021-07-08T12:11:08.697837Z","shell.execute_reply.started":"2021-07-08T12:11:08.358067Z","shell.execute_reply":"2021-07-08T12:11:08.696476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.2) With KBOX data\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX_scaled = scaler.fit_transform(X)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.142723Z","iopub.status.idle":"2021-07-06T08:34:50.143165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration options\nepsilon = 1000.0\nmin_samples = 40\ncluster_method = 'xi'\nmetric = 'minkowski'\n\n# Compute OPTICS\ndb = OPTICS(max_eps=epsilon, min_samples=min_samples, cluster_method=cluster_method, metric=metric).fit(X_scaled)\nlabels = db.labels_","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.1441Z","iopub.status.idle":"2021-07-06T08:34:50.144504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab = np.unique(labels)\nlab","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.145413Z","iopub.status.idle":"2021-07-06T08:34:50.145833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_clusters = len(np.unique(labels))\nno_noise = np.sum(np.array(labels) == -1, axis=0)\n\nprint('Estimated no. of clusters: %d' % no_clusters)\nprint('Estimated no. of noise points: %d' % no_noise)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.146825Z","iopub.status.idle":"2021-07-06T08:34:50.147224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled_df = pd.DataFrame(X_scaled) ","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.148095Z","iopub.status.idle":"2021-07-06T08:34:50.148493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate scatter plot for training data\ncolors = list(map(lambda x: '#3b4cc0' if x == 1 else '#b40426', labels))\nplt.scatter(X_scaled_df.iloc[:,0], X_scaled_df.iloc[:,2], c=colors, marker=\"o\", picker=True)\nplt.title(f'OPTICS clustering')\nplt.xlabel('Axis X[0]')\nplt.ylabel('Axis X[1]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.149507Z","iopub.status.idle":"2021-07-06T08:34:50.149952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate reachability plot\nreachability = db.reachability_[db.ordering_]\nplt.plot(reachability)\nplt.title('Reachability plot')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.150803Z","iopub.status.idle":"2021-07-06T08:34:50.151195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3) Mean-Shift","metadata":{}},{"cell_type":"code","source":"# The following bandwidth can be automatically detected using\nbandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\n\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(X)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.152142Z","iopub.status.idle":"2021-07-06T08:34:50.152535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.2) With KBOX data\n","metadata":{}},{"cell_type":"code","source":"X_scaled_df = pd.DataFrame(X_scaled) ","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.15889Z","iopub.status.idle":"2021-07-06T08:34:50.159379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The following bandwidth can be automatically detected using\nbandwidth = estimate_bandwidth(X_scaled_df, quantile=0.1, n_samples=100)\n\nms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\nms.fit(X_scaled_df)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\nprint(\"number of estimated clusters : %d\" % n_clusters_)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.160504Z","iopub.status.idle":"2021-07-06T08:34:50.160951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Generate sample data\n#centers = [[1, 1], [-1, -1], [1, -1]]\n#X, _ = make_blobs(n_samples=10000, centers=centers, cluster_std=0.6)\n#\n## #############################################################################\n## Compute clustering with MeanShift\n#\n## The following bandwidth can be automatically detected using\n#bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\n#\n#ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n#ms.fit(X)\n#labels = ms.labels_\n#cluster_centers = ms.cluster_centers_\n#\n#labels_unique = np.unique(labels)\n#n_clusters_ = len(labels_unique)\n#\n#print(\"number of estimated clusters : %d\" % n_clusters_)\n#\n## #############################################################################\n## Plot result\n#import matplotlib.pyplot as plt\n#from itertools import cycle\n#\n#plt.figure(1)\n#plt.clf()\n#\n#colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n#for k, col in zip(range(n_clusters_), colors):\n#    my_members = labels == k\n#    cluster_center = cluster_centers[k]\n#    plt.plot(X[my_members, 0], X[my_members, 1], col + '.')\n#    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n#             markeredgecolor='k', markersize=14)\n#plt.title('Estimated number of clusters: %d' % n_clusters_)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.161999Z","iopub.status.idle":"2021-07-06T08:34:50.162438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Normalization ","metadata":{}},{"cell_type":"code","source":"X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\ny = train['Key-P20'].copy()\n\n#X.values.flatten()\n#sum(n < 0 for n in X.values.flatten())","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.163442Z","iopub.status.idle":"2021-07-06T08:34:50.16393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.165186Z","iopub.status.idle":"2021-07-06T08:34:50.165657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(-1, 1))\nX_norm =  scaler.fit_transform(X[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']])\nX_norm = pd.DataFrame(X_norm, columns=['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.16661Z","iopub.status.idle":"2021-07-06T08:34:50.167091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_norm['CodigoCLI'] = X['CodigoCLI']","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.168131Z","iopub.status.idle":"2021-07-06T08:34:50.168581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X_norm.iloc[:,2], X_norm.iloc[:,4])\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Data Distribution')\nplt.show()\n#X_norm.drop('CodigoCLI', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.169576Z","iopub.status.idle":"2021-07-06T08:34:50.170015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X_norm.iloc[:,2], X_norm.iloc[:,3])\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Data Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.171Z","iopub.status.idle":"2021-07-06T08:34:50.171416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X_norm.iloc[:,2], X_norm.index,)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Data Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:34:50.172316Z","iopub.status.idle":"2021-07-06T08:34:50.172719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Initialization Genetic Algorithms","metadata":{}},{"cell_type":"code","source":"data = '../input/tfm-data-2/bdims.csv'","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:58:46.266221Z","iopub.execute_input":"2021-07-06T08:58:46.266627Z","iopub.status.idle":"2021-07-06T08:58:46.271903Z","shell.execute_reply.started":"2021-07-06T08:58:46.266593Z","shell.execute_reply":"2021-07-06T08:58:46.27025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = df_s[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n                '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n                'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n                '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',\n                \n                'Key-P20', 'Key-B20', 'Key-V20', 'Key-QV20', 'Key-QM20', 'Key-R20', 'Key-WCI20',\n                'KHR20', 'KVP20', 'KRB20', 'KeyQVM20', 'Short-KHR20', 'Short-KVP20', 'Short-KRB20', 'Short-KeyQVM20',]].copy()\n\ntrain_x.dropna(axis=0, inplace=True)\ntrain_x.reset_index(drop = True, inplace=True)\n\n#X = train[['CodigoCLI', 'Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19']].copy()\nX = train_x[['Vta19', 'VtaTar19', 'VtaCos19', 'Rappel19', 'MBto19', \n             '%ContVta19', 'CtVta19', '%ContMBto19', 'CtMBto19', ##kbox data\n             'PosAbcVta19', '%PosAbcVta19', 'AcuVta19', '%AcuVta19', 'PosAbcMBto',\n             '%PosAbcMBto19', 'AcuMBto19', '%AcuMBto19',]].copy()\n\nscaler = MinMaxScaler(feature_range=(100, 1000))\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:48:57.739203Z","iopub.execute_input":"2021-07-08T07:48:57.73956Z","iopub.status.idle":"2021-07-08T07:48:57.76783Z","shell.execute_reply.started":"2021-07-08T07:48:57.739528Z","shell.execute_reply":"2021-07-08T07:48:57.766818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled = scaler.fit_transform(X.iloc[:,:2])\nX_scaled","metadata":{"execution":{"iopub.status.busy":"2021-07-07T21:47:37.603073Z","iopub.execute_input":"2021-07-07T21:47:37.603417Z","iopub.status.idle":"2021-07-07T21:47:37.613118Z","shell.execute_reply.started":"2021-07-07T21:47:37.603368Z","shell.execute_reply":"2021-07-07T21:47:37.612262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data = np.genfromtxt(data, delimiter=',', skip_header=1)\n#data = data[:,-3] # select the \"weight\" column in the dataset\n\n#data = np.array(X)\n\ndata = X_scaled\ndata = data[:,1]\n\nN = data.shape[0] # number of data points\nK = 6 # 4 components GMM\ntot_iterations = 100 # stopping criterium","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:00:22.628042Z","iopub.execute_input":"2021-07-08T08:00:22.628436Z","iopub.status.idle":"2021-07-08T08:00:22.633726Z","shell.execute_reply.started":"2021-07-08T08:00:22.628404Z","shell.execute_reply":"2021-07-08T08:00:22.632745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step-1 (Init)\n#mu = np.random.uniform(low=42.0, high=95.0, size=K) # mean\n#sigma = np.random.uniform(low=5.0, high=10.0, size=K) # standard deviaiton\n\nmu_high = np.mean(data) + np.std(data)\nmu_low = np.mean(data) - np.std(data)\n\nsigma_high = np.var(data) + np.std(data) #(np.var(data)/10/2/2) + (np.var(data)/10/2/2)/2 \nsigma_low =  np.var(data) - np.std(data) #(np.var(data)/10/2/2) - (np.var(data)/10/2/2)/2\n\nmu = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\nsigma = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n\npi = np.ones(K) * (1.0/K) # mixing coefficients\nr = np.zeros([K,N]) # responsibilities\nnll_list = list() # used to store the neg log-likelihood (nll)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T15:34:36.155904Z","iopub.execute_input":"2021-07-06T15:34:36.156408Z","iopub.status.idle":"2021-07-06T15:34:36.164579Z","shell.execute_reply.started":"2021-07-06T15:34:36.156375Z","shell.execute_reply":"2021-07-06T15:34:36.163776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for iteration in range(tot_iterations):\n    #print(mu)\n    \n    # Step-2 (E-Step)\n    for k in range(K):\n        #print(norm.pdf(x=data, loc=mu[k], scale=sigma[k]))\n        r[k,:] = pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n    r = r / np.sum(r, axis=0) #[K,N] -> [N]\n    #print(r)\n        \n    # Step-3 (M-Step)\n    N_k = np.sum(r, axis=1) #[K,N] -> [K]\n    #print('yo',N_k)\n    for k in range(K):\n        mu[k] = np.sum(r[k,:] * data) / N_k[k] # update mean\n        #print(mu[k], N_k[k])\n        numerator = r[k] * (data - mu[k])**2\n        sigma[k] = np.sqrt(np.sum(numerator) / N_k[k]) # update std\n    pi = N_k/N # update mixing coefficient\n    #print(mu, numerator, sigma, pi)\n    \n    # Estimate likelihood and print info\n    likelihood = 0.0\n    for k in range(K):\n        likelihood += pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n    nll_list.append(-np.sum(np.log(likelihood)))\n    #print(\"Iteration: \"+str(iteration)+\"; NLL: \"+str(nll_list[-1]))\n    #print(\"Mean \"+str(mu)+\"\\nStd \"+ str(sigma)+\"\\nWeights \"+ str(pi)+\"\\n\")\n   \n    # Step-4 (Check)\n    if(iteration==tot_iterations-1): break","metadata":{"execution":{"iopub.status.busy":"2021-07-06T12:56:57.638423Z","iopub.execute_input":"2021-07-06T12:56:57.638808Z","iopub.status.idle":"2021-07-06T12:56:57.969587Z","shell.execute_reply.started":"2021-07-06T12:56:57.638774Z","shell.execute_reply":"2021-07-06T12:56:57.968561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define and set function to create a candidate solution representation\ndef create_individual(data):\n    individual = data[:]\n    random.shuffle(individual)\n    return individual\n\n\n# define and set the GA's crossover operation\ndef crossover_function(parent_1, parent_2):\n    #crossover_index = random.randrange(1, (len(parent_1)/2) )\n    #child_1a = parent_1[:crossover_index]\n    #child_1b = [i for i in parent_2 if i not in child_1a]\n    #child_1 = child_1a + child_1b\n    \n    child_1a = random.sample(parent_1, 3) #6:3\n    child_1b = [i for i in parent_2 if i not in child_1a]\n    child_1b = random.sample(child_1b, 3) #3:1, 4:2, 5:3, 6:3\n    child_1 = child_1a + child_1b\n    \n    #child_2a = parent_2[crossover_index:]\n    #child_2b = [i for i in parent_1 if i not in child_2a]\n    #child_2 = child_2a + child_2b\n    \n    child_2a = random.sample(parent_2, 3) #6:3\n    child_2b = [i for i in parent_1 if i not in child_2a]\n    child_2b = random.sample(child_2b, 3) #3:1, 4:2, 5:3, 6:3\n    child_2 = child_2a + child_2b       \n\n    return child_1, child_2\n\n\n# define and set the GA's mutation operation\ndef mutate_function(individual):\n    mutate_index1 = random.randrange(len(individual))\n    mutate_index2 = random.randrange(len(individual))\n    #print(mutate_index1, mutate_index2)\n    individual[mutate_index1], individual[mutate_index2] = individual[mutate_index2], individual[mutate_index1]\n    #return individual[mutate_index1], individual[mutate_index2]\n\n# define and set the GA's selection operation\ndef selection(population):\n    return random.choice(population)\n\ndef random_selection(population):\n            \"\"\"Select and return a random member of the population.\"\"\"\n            return self.random.choice(population)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:01:04.41949Z","iopub.execute_input":"2021-07-08T08:01:04.419903Z","iopub.status.idle":"2021-07-08T08:01:04.600907Z","shell.execute_reply.started":"2021-07-08T08:01:04.419866Z","shell.execute_reply":"2021-07-08T08:01:04.599842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mu_sigma_population_creator(data):\n    mu_list_1 = []\n    mu_list_2 = []\n    \n    sigma_list_1 = []\n    sigma_list_2 = []\n    \n    mu_high = np.mean(data) + np.std(data)\n    mu_low = np.mean(data) - np.std(data)\n\n    sigma_high = np.var(data) + np.std(data)  \n    sigma_low =  np.var(data) - np.std(data) \n  \n    for i in range(25):        \n        \n        mu_1 = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n        sigma_1 = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n        #mu_1 = np.random.uniform(low=42.0, high=95.0, size=K) # mean\n        #sigma_1 = np.random.uniform(low=5.0, high=10.0, size=K) # standard deviaiton\n        mu_list_1.append(list(mu_1))\n        sigma_list_1.append(list(sigma_1))\n    \n    for y in range(25):\n        mu_2 = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n        sigma_2 = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n        #mu_2 = np.random.uniform(low=42.0, high=95.0, size=K) # mean\n        #sigma_2 = np.random.uniform(low=5.0, high=10.0, size=K) # standard deviaiton\n        mu_list_2.append(list(mu_2))\n        sigma_list_2.append(list(sigma_2))\n        \n    return (mu_list_1, mu_list_2, sigma_list_1, sigma_list_2)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:01:05.731858Z","iopub.execute_input":"2021-07-08T08:01:05.732399Z","iopub.status.idle":"2021-07-08T08:01:05.741362Z","shell.execute_reply.started":"2021-07-08T08:01:05.732348Z","shell.execute_reply":"2021-07-08T08:01:05.740552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def master_mu_sigma_population_creator(data):\n    \n    master_mu_list_1 = []\n    master_mu_list_2 = []\n    \n    master_sigma_list_1 = []\n    master_sigma_list_2 = []\n    \n    for i in range(17):\n        #data = data[:,i]\n    \n        mu_list_1 = []\n        mu_list_2 = []\n\n        sigma_list_1 = []\n        sigma_list_2 = []\n\n        mu_high = np.mean(data[:,i]) + np.std(data[:,i])\n        mu_low = np.mean(data[:,i]) - np.std(data[:,i])\n\n        sigma_high = np.var(data[:,i]) + np.std(data[:,i])  \n        sigma_low =  np.var(data[:,i]) - np.std(data[:,i]) \n\n        for i in range(25):\n\n            mu_1 = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n            sigma_1 = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n            #mu_1 = np.random.uniform(low=42.0, high=95.0, size=K) # mean\n            #sigma_1 = np.random.uniform(low=5.0, high=10.0, size=K) # standard deviaiton\n            mu_list_1.append(list(mu_1))\n            sigma_list_1.append(list(sigma_1))\n        \n        master_mu_list_1.append(mu_list_1)\n        master_sigma_list_1.append(sigma_list_1)\n\n        for y in range(25):\n            mu_2 = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n            sigma_2 = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n            #mu_2 = np.random.uniform(low=42.0, high=95.0, size=K) # mean\n            #sigma_2 = np.random.uniform(low=5.0, high=10.0, size=K) # standard deviaiton\n            mu_list_2.append(list(mu_2))\n            sigma_list_2.append(list(sigma_2))\n        \n        master_mu_list_2.append(mu_list_2)\n        master_sigma_list_2.append(sigma_list_2)\n\n\n        \n    return (master_mu_list_1, master_mu_list_2, master_sigma_list_1, master_sigma_list_2)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:01:08.414956Z","iopub.execute_input":"2021-07-08T08:01:08.415489Z","iopub.status.idle":"2021-07-08T08:01:08.426467Z","shell.execute_reply.started":"2021-07-08T08:01:08.415441Z","shell.execute_reply":"2021-07-08T08:01:08.425699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"population = mu_sigma_population_creator(data)\nparent_1, parent_2 = population[0], population[1]\nparent_3, parent_4 = population[2], population[3]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:02:19.304064Z","iopub.execute_input":"2021-07-08T08:02:19.304472Z","iopub.status.idle":"2021-07-08T08:02:19.312Z","shell.execute_reply.started":"2021-07-08T08:02:19.304438Z","shell.execute_reply":"2021-07-08T08:02:19.310624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"population = master_mu_sigma_population_creator(data)\nparent_1, parent_2 = population[0], population[1]\nparent_3, parent_4 = population[2], population[3]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:49:21.917086Z","iopub.execute_input":"2021-07-08T07:49:21.917462Z","iopub.status.idle":"2021-07-08T07:49:21.948405Z","shell.execute_reply.started":"2021-07-08T07:49:21.917429Z","shell.execute_reply":"2021-07-08T07:49:21.947383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crossover_mutation(parent_1, parent_2, crossover_prob = 0.8, mutation_prob = 0.2):\n    \n    new_population = []\n    population_size = 25\n    child_1, child_2 = parent_1, parent_2\n    \n    for i in range(50):\n        while len(new_population) < population_size:\n\n            can_crossover = random.random() <= crossover_prob\n            can_mutate = random.random() <= mutation_prob\n\n            if can_crossover:\n                child_1[i], child_2[i] = crossover_function(parent_1[i], parent_2[i])\n\n            if can_mutate:\n                mutate_function(child_1[i])\n                mutate_function(child_2[i])\n\n            new_population.append(child_1[i])\n            if len(new_population) < population_size:\n                new_population.append(child_2[i])\n        \n    return new_population","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:01:17.719075Z","iopub.execute_input":"2021-07-08T08:01:17.719438Z","iopub.status.idle":"2021-07-08T08:01:17.728138Z","shell.execute_reply.started":"2021-07-08T08:01:17.719407Z","shell.execute_reply":"2021-07-08T08:01:17.727075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def master_crossover_mutation(master_parent_1, master_parent_2, crossover_prob = 0.8, mutation_prob = 0.2):\n    \n    new_populations = []\n\n    for i in range(17):\n        \n        new_population = []\n        population_size = 25\n        parent_1, parent_2 = master_parent_1[i], master_parent_2[i]\n        child_1, child_2 = parent_1, parent_2\n\n        for i in range(50):\n            while len(new_population) < population_size:\n\n                can_crossover = random.random() <= crossover_prob\n                can_mutate = random.random() <= mutation_prob\n\n                if can_crossover:\n                    child_1[i], child_2[i] = crossover_function(parent_1[i], parent_2[i])\n\n                if can_mutate:\n                    mutate_function(child_1[i])\n                    mutate_function(child_2[i])\n\n                new_population.append(child_1[i])\n                if len(new_population) < population_size:\n                    new_population.append(child_2[i])\n        \n        new_populations.append(new_population)\n\n    return new_populations","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:51:15.00247Z","iopub.execute_input":"2021-07-08T07:51:15.00313Z","iopub.status.idle":"2021-07-08T07:51:15.011181Z","shell.execute_reply.started":"2021-07-08T07:51:15.003092Z","shell.execute_reply":"2021-07-08T07:51:15.01042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_population_mu = crossover_mutation(parent_1 = parent_1, parent_2 = parent_2)\nnew_population_sigma = crossover_mutation(parent_1 = parent_3, parent_2 = parent_4)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:02:23.883982Z","iopub.execute_input":"2021-07-08T08:02:23.884325Z","iopub.status.idle":"2021-07-08T08:02:23.889046Z","shell.execute_reply.started":"2021-07-08T08:02:23.884294Z","shell.execute_reply":"2021-07-08T08:02:23.888008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_population_mu = master_crossover_mutation(master_parent_1 = parent_1, master_parent_2 = parent_2)\nnew_population_sigma = master_crossover_mutation(master_parent_1 = parent_3, master_parent_2 = parent_4)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:41:44.634514Z","iopub.execute_input":"2021-07-08T07:41:44.635069Z","iopub.status.idle":"2021-07-08T07:41:44.64929Z","shell.execute_reply.started":"2021-07-08T07:41:44.635034Z","shell.execute_reply":"2021-07-08T07:41:44.648488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distributions(data, data_sampled, mu, sigma, K, color=\"green\", color_sampled=\"red\", name='plot.png'):\n    #matplotlib.rcParams['text.usetex'] = True\n    #plt.rcParams.update({'font.size': 16})    \n    data_sampled = np.clip(data_sampled, np.min(data), np.max(data))\n    plt.hist(data, bins=15, color=color, alpha=0.45, density=True)\n    plt.hist(data_sampled, bins=15, range=(np.min(data), np.max(data)), color=color_sampled, alpha=0.45, density=True)\n    for k in range(K):\n        curve = np.linspace(mu[k] - 10*sigma[k], mu[k] + 10*sigma[k], 100)\n        color = np.random.rand(3)\n        plt.plot(curve, stats.norm.pdf(curve, mu[k], sigma[k]), color=color, linestyle=\"--\", linewidth=3)\n    plt.ylabel(r\"$p(x)$\")\n    plt.xlabel(r\"$x$\")\n    plt.tight_layout()\n    plt.xlim(20, 120)\n    plt.savefig(name, dpi=200)\n    plt.show()\n\ndef plot_likelihood(nll_list, num):\n    #matplotlib.rcParams['text.usetex'] = True\n    \n    #plt.rcParams.update({'font.size': 16})\n    plt.plot(np.arange(len(nll_list)), nll_list, color=\"black\", linestyle=\"--\", linewidth=3)\n    plt.ylabel(r\"(negative) log-likelihood\")\n    plt.xlabel(r\"iteration\")\n    plt.tight_layout()\n    plt.xlim(0, len(nll_list))\n    #plt.savefig('nll1.png', dpi=200)\n    plt.savefig('./real_data_{}.png'.format(num), dpi = 200)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:41:03.674823Z","iopub.execute_input":"2021-07-08T07:41:03.675168Z","iopub.status.idle":"2021-07-08T07:41:03.686754Z","shell.execute_reply.started":"2021-07-08T07:41:03.675138Z","shell.execute_reply":"2021-07-08T07:41:03.685934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def likelihood_calculator(dt, mu_list, sigma_list):    \n    #data = np.genfromtxt(dt, delimiter=',', skip_header=1)#[:,-2]\n    #data = data[:,-3]\n    data = dt\n    N = data.shape[0]\n    K = 6 # two components GMM\n    tot_iterations = 100 # stopping criteria\n\n    # Step-1 (Init)\n    #mu = np.random.uniform(low=42.0, high=95.0, size=K)\n    #sigma = np.random.uniform(low=5.0, high=10.0, size=K)\n    #pi = np.ones(K) * (1.0/K) # mixing coefficients\n    #r = np.zeros([K,N]) # responsibilities\n    #nll_list = list() # store the neg log-likelihood\n    \n    last_nll_list = list() ## Used to collect the last nulls for the mu\n    complete_nll_list = list() ## Used to collect all the null lists\n    \n    #for \n    #mu_list_copy = mu_list.copy()\n    #sigma_list_copy = sigma_list.copy()\n    num = 1\n    for mu_elem, sigma_elem in zip(mu_list, sigma_list):\n        #print(mu_elem)\n        #print(sigma_elem)\n        \n        #mu_high = np.mean(data) + np.std(data)\n        #mu_low = np.mean(data) - np.std(data)\n        \n        #sigma_high = np.var(data) + np.std(data)  \n        #sigma_low =  np.var(data) - np.std(data) \n\n        #mu = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n        #sigma = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n    \n        \n        pi = np.ones(K) * (1.0/K) # mixing coefficients\n        r = np.zeros([K,N]) # responsibilities\n        nll_list = list() # store the neg log-likelihood\n        \n        mu = mu_elem\n        sigma = sigma_elem\n        \n        for iteration in range(tot_iterations):  \n            # Step-2 (E-Step)\n            for k in range(K):   \n                r[k,:] = pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n            r = r / np.sum(r, axis=0) #[K,N] -> [N]\n\n            # Step-3 (M-Step)\n            N_k = np.sum(r, axis=1) #[K,N] -> [K]\n            for k in range(K): \n                # update means\n                mu[k] = np.sum(r[k,:] * data) / N_k[k]        \n                # update variances\n                numerator = r[k] * (data - mu[k])**2\n                sigma[k] = np.sqrt(np.sum(numerator) / N_k[k])        \n            # update weights\n            pi = N_k/N \n\n            likelihood = 0.0\n\n            for k in range(K):\n                likelihood += pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n            \n            nll_list.append(-np.sum(np.log(likelihood)))        \n\n        \n            # Check for invalid negative log-likelihood (NLL)\n            # The NLL is invalid if NLL_t-1 < NLL_t\n            # Note that this can happen for round-off errors.\n            if(len(nll_list)>=2):\n                if(nll_list[-2]<nll_list[-1]): raise Exception(\"[ERROR] invalid NLL: \"+str(nll_list[-2:]))\n\n            #print(\"Iteration: \" + str(iteration) + \"; NLL: \" + str(nll_list[-1]))\n            #print(\"Mean \" + str(mu) + \"\\nStd \" + str(sigma) + \"\\nWeights \" + str(pi) + \"\\n\")     \n\n            # Step-4 (Check)\n            if(iteration==tot_iterations-1): \n                last_nll_list.append(nll_list[-1])\n                break # check iteration\n        print(str(nll_list[-1]))\n        plot_likelihood(nll_list, num)\n        num = num +1\n    #data_gmm = sampler(pi, mu, sigma, N=1000)\n    #plot_distributions(data, data_gmm, mu, sigma, K, color=\"green\", color_sampled=\"red\", name=\"plot_sampler.png\")\n    \n    return last_nll_list   \n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:05:36.098825Z","iopub.execute_input":"2021-07-08T08:05:36.099173Z","iopub.status.idle":"2021-07-08T08:05:36.115794Z","shell.execute_reply.started":"2021-07-08T08:05:36.099143Z","shell.execute_reply":"2021-07-08T08:05:36.114758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_population_mu_copy = copy.deepcopy(new_population_mu)\nnew_population_sigma_copy = copy.deepcopy(new_population_sigma)\n\na = likelihood_calculator(data, new_population_mu_copy, new_population_sigma_copy)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T08:05:37.650775Z","iopub.execute_input":"2021-07-08T08:05:37.651111Z","iopub.status.idle":"2021-07-08T08:05:56.515659Z","shell.execute_reply.started":"2021-07-08T08:05:37.651083Z","shell.execute_reply":"2021-07-08T08:05:56.514543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def master_likelihood_calculator(master_dt, master_mu_list, master_sigma_list):    \n    #data = np.genfromtxt(dt, delimiter=',', skip_header=1)#[:,-2]\n    #data = data[:,-\n    master_final_mu = []\n    master_final_sigma = []\n    master_final_pi = []\n    \n    final_mu_list = []\n    final_sigma_list = []\n    final_pi_list = []\n    \n    for i in range(17):\n        data = master_dt[:,i]\n        N = data.shape[0]\n        K = 5 # two components GMM\n        tot_iterations = 100 # stopping criteria\n\n        # Step-1 (Init)\n        #mu = np.random.uniform(low=42.0, high=95.0, size=K)\n        #sigma = np.random.uniform(low=5.0, high=10.0, size=K)\n        #pi = np.ones(K) * (1.0/K) # mixing coefficients\n        #r = np.zeros([K,N]) # responsibilities\n        #nll_list = list() # store the neg log-likelihood\n\n        last_nll_list = list() ## Used to collect the last nulls for the mu\n        complete_nll_list = list() ## Used to collect all the null lists\n\n\n        #mu_list_copy = mu_list.copy()\n        #sigma_list_copy = sigma_list.copy()\n        \n        num = 1\n\n        mu_list = master_mu_list[i]\n        sigma_list = master_sigma_list[i]\n\n        for mu_elem, sigma_elem in zip(mu_list, sigma_list):\n            #print(mu_elem)\n            #print(sigma_elem)\n\n            pi = np.ones(K) * (1.0/K) # mixing coefficients\n            r = np.zeros([K,N]) # responsibilities\n            nll_list = list() # store the neg log-likelihood\n\n            mu = mu_elem\n            sigma = sigma_elem\n            \n\n            for iteration in range(tot_iterations):  \n                # Step-2 (E-Step)\n                for k in range(K):   \n                    r[k,:] = pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n                r = r / np.sum(r, axis=0) #[K,N] -> [N]\n\n                # Step-3 (M-Step)\n                N_k = np.sum(r, axis=1) #[K,N] -> [K]\n                for k in range(K): \n                    # update means\n                    mu[k] = np.sum(r[k,:] * data) / N_k[k]        \n                    # update variances\n                    numerator = r[k] * (data - mu[k])**2\n                    sigma[k] = np.sqrt(np.sum(numerator) / N_k[k])        \n                # update weights\n                pi = N_k/N \n\n                likelihood = 0.0\n\n                for k in range(K):\n                    likelihood += pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n\n                nll_list.append(-np.sum(np.log(likelihood)))        \n\n\n                # Check for invalid negative log-likelihood (NLL)\n                # The NLL is invalid if NLL_t-1 < NLL_t\n                # Note that this can happen for round-off errors.\n                if(len(nll_list)>=2):\n                    if(nll_list[-2]<nll_list[-1]): raise Exception(\"[ERROR] invalid NLL: \"+str(nll_list[-2:]))\n\n                #print(\"Iteration: \" + str(iteration) + \"; NLL: \" + str(nll_list[-1]))\n                #print(\"Mean \" + str(mu) + \"\\nStd \" + str(sigma) + \"\\nWeights \" + str(pi) + \"\\n\")     \n\n                # Step-4 (Check)\n                if(iteration == tot_iterations-1): \n                    last_nll_list.append(nll_list[-1])\n                    break # check iteration\n                    \n            if min(mu) > 0: \n                final_mu_list.append(mu)\n            if min(sigma) > 0: \n                final_sigma_list.append(sigma)\n            if min(pi) > 0: \n                final_pi_list.append(pi)\n        \n            #plot_likelihood(nll_list, num)\n            num = num +1\n        #data_gmm = sampler(pi, mu, sigma, N=1000)\n        #plot_distributions(data, data_gmm, mu, sigma, K, color=\"green\", color_sampled=\"red\", name=\"plot_sampler.png\")\n        master_final_mu.append(final_mu_list)\n        master_final_sigma.append(final_sigma_list)\n        master_final_pi.append(final_pi_list)\n        \n        \n    #return last_nll_list   \n    return (master_final_mu, master_final_sigma, master_final_pi)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:50:07.452175Z","iopub.execute_input":"2021-07-08T07:50:07.452529Z","iopub.status.idle":"2021-07-08T07:50:07.472197Z","shell.execute_reply.started":"2021-07-08T07:50:07.452498Z","shell.execute_reply":"2021-07-08T07:50:07.471084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu_means = []\nsigma_means = []\npi_means = []\n\nfor i in range(17):\n    mu_means.append(np.average(a[0][i], axis = 0))\n    sigma_means.append(np.mean(a[1][i], axis = 0))\n    pi_means.append(np.average(a[2][i], axis = 0))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:32:26.130761Z","iopub.execute_input":"2021-07-08T07:32:26.131139Z","iopub.status.idle":"2021-07-08T07:32:26.159316Z","shell.execute_reply.started":"2021-07-08T07:32:26.131101Z","shell.execute_reply":"2021-07-08T07:32:26.158409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu_means","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:43:29.103111Z","iopub.execute_input":"2021-07-08T07:43:29.103478Z","iopub.status.idle":"2021-07-08T07:43:29.114335Z","shell.execute_reply.started":"2021-07-08T07:43:29.103447Z","shell.execute_reply":"2021-07-08T07:43:29.113179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu_means = []\nsigma_means = []\npi_means = []\n\nfor i in range(17):\n    mu_means.append(np.average(b_1[i], axis = 0))\n    sigma_means.append(np.mean(b_2[i], axis = 0))\n    pi_means.append(np.average(b_3[i], axis = 0))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:43:20.210373Z","iopub.execute_input":"2021-07-08T07:43:20.210777Z","iopub.status.idle":"2021-07-08T07:43:20.240996Z","shell.execute_reply.started":"2021-07-08T07:43:20.210742Z","shell.execute_reply":"2021-07-08T07:43:20.239793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(17):\n    b_1[i] = (list(filter(lambda x: x, b_1[i])))\n    b_2[i] = (list(filter(lambda x: x, b_2[i])))\n    b_3[i] = (list(filter(lambda x: x, b_3[i])))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:43:16.513564Z","iopub.execute_input":"2021-07-08T07:43:16.513978Z","iopub.status.idle":"2021-07-08T07:43:16.521113Z","shell.execute_reply.started":"2021-07-08T07:43:16.513945Z","shell.execute_reply":"2021-07-08T07:43:16.519857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_1 = [ [[x for x in y if not np.isnan(x)] for y in z] for z in a[0] ]\nb_2 = [ [[x for x in y if not np.isnan(x)] for y in z] for z in a[1] ]\nb_3 = [ [[x for x in y if not np.isnan(x)] for y in z] for z in a[2] ]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:43:13.371371Z","iopub.execute_input":"2021-07-08T07:43:13.371764Z","iopub.status.idle":"2021-07-08T07:43:13.497843Z","shell.execute_reply.started":"2021-07-08T07:43:13.371729Z","shell.execute_reply":"2021-07-08T07:43:13.496767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_population_mu_copy = copy.deepcopy(new_population_mu)\nnew_population_sigma_copy = copy.deepcopy(new_population_sigma)\n\na = master_likelihood_calculator(data, new_population_mu_copy, new_population_sigma_copy)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:41:53.806222Z","iopub.execute_input":"2021-07-08T07:41:53.806758Z","iopub.status.idle":"2021-07-08T07:43:10.068141Z","shell.execute_reply.started":"2021-07-08T07:41:53.80672Z","shell.execute_reply":"2021-07-08T07:43:10.067366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len((list(filter(lambda x: x, a[0]))))\nlen((list(filter(lambda x: x, a[1]))))\nlen((list(filter(lambda x: x, a[2]))))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T07:15:19.973257Z","iopub.execute_input":"2021-07-08T07:15:19.973633Z","iopub.status.idle":"2021-07-08T07:15:19.981386Z","shell.execute_reply.started":"2021-07-08T07:15:19.973587Z","shell.execute_reply":"2021-07-08T07:15:19.980374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distributions(data, data_sampled, mu, sigma, K, color=\"green\", color_sampled=\"red\", name='plot.png'):\n    matplotlib.rcParams['text.usetex'] = True\n    plt.rcParams.update({'font.size': 16})    \n    data_sampled = np.clip(data_sampled, np.min(data), np.max(data))\n    plt.hist(data, bins=15, color=color, alpha=0.45, density=True)\n    plt.hist(data_sampled, bins=15, range=(np.min(data), np.max(data)), color=color_sampled, alpha=0.45, density=True)\n    for k in range(K):\n        curve = np.linspace(mu[k] - 10*sigma[k], mu[k] + 10*sigma[k], 100)\n        color = np.random.rand(3)\n        plt.plot(curve, stats.norm.pdf(curve, mu[k], sigma[k]), color=color, linestyle=\"--\", linewidth=3)\n    plt.ylabel(r\"$p(x)$\")\n    plt.xlabel(r\"$x$\")\n    plt.tight_layout()\n    plt.xlim(20, 120)\n    plt.savefig(name, dpi=200)\n    plt.show()\n\ndef plot_likelihood(nll_list):\n    #matplotlib.rcParams['text.usetex'] = True\n    plt.rcParams.update({'font.size': 16})\n    plt.plot(np.arange(len(nll_list)), nll_list, color=\"black\", linestyle=\"--\", linewidth=3)\n    plt.ylabel(r\"(negative) log-likelihood\")\n    plt.xlabel(r\"iteration\")\n    plt.tight_layout()\n    plt.xlim(0, len(nll_list))\n    plt.savefig('nll.png', dpi=200)\n    plt.show()\n    \ndef sampler(pi, mu, sigma, N):\n    data = list()\n    for n in range(N):\n        k = np.random.choice(len(pi), p=pi)\n        sample = np.random.normal(loc=mu[k], scale=sigma[k])\n        data.append(sample)\n    return data\n\ndef main(dt):    \n    #data = np.genfromtxt(dt, delimiter=',', skip_header=1)#[:,-2]\n    #data = data[:,-3]\n    \n    N = dt.shape[0]\n    K = 4 # two components GMM\n    tot_iterations = 100 # stopping criteria\n\n    # Step-1 (Init)\n    mu_high = np.mean(data) + np.std(data)\n    mu_low = np.mean(data) - np.std(data)\n    \n    sigma_high = np.var(data) + np.std(data)  \n    sigma_low =  np.var(data) - np.std(data) \n\n    mu = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n    sigma = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n\n    #mu = np.random.uniform(low=42.0, high=95.0, size=K)\n    #sigma = np.random.uniform(low=5.0, high=10.0, size=K)\n    \n    pi = np.ones(K) * (1.0/K) # mixing coefficients\n    r = np.zeros([K,N]) # responsibilities\n    nll_list = list() # store the neg log-likelihood\n\n    for iteration in range(tot_iterations):  \n        # Step-2 (E-Step)\n        for k in range(K):\n            r[k,:] = pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n        r = r / np.sum(r, axis=0) #[K,N] -> [N]\n        \n        # Step-3 (M-Step)\n        N_k = np.sum(r, axis=1) #[K,N] -> [K]\n        for k in range(K): \n            # update means\n            mu[k] = np.sum(r[k,:] * data) / N_k[k]        \n            # update variances\n            numerator = r[k] * (data - mu[k])**2\n            sigma[k] = np.sqrt(np.sum(numerator) / N_k[k])        \n        # update weights\n        pi = N_k/N \n        \n        likelihood = 0.0\n        for k in range(K):\n            likelihood += pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n        nll_list.append(-np.sum(np.log(likelihood)))        \n        # Check for invalid negative log-likelihood (NLL)\n        # The NLL is invalid if NLL_t-1 < NLL_t\n        # Note that this can happen for round-off errors.\n        if(len(nll_list)>=2):\n            if(nll_list[-2]<nll_list[-1]): raise Exception(\"[ERROR] invalid NLL: \"+str(nll_list[-2:]))\n   \n        print(\"Iteration: \" + str(iteration) + \"; NLL: \" + str(nll_list[-1]))\n        print(\"Mean \" + str(mu) + \"\\nStd \" + str(sigma) + \"\\nWeights \" + str(pi) + \"\\n\")     \n   \n        # Step-4 (Check)\n        if(iteration==tot_iterations-1): break # check iteration\n    \n    return nll_list\n    \n    #plot_likelihood(nll_list)\n    #data_gmm = sampler(pi, mu, sigma, N=1000)\n    #plot_distributions(data, data_gmm, mu, sigma, K, color=\"green\", color_sampled=\"red\", name=\"plot_sampler.png\")","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:38:07.231894Z","iopub.execute_input":"2021-07-06T14:38:07.2324Z","iopub.status.idle":"2021-07-06T14:38:07.258056Z","shell.execute_reply.started":"2021-07-06T14:38:07.232367Z","shell.execute_reply":"2021-07-06T14:38:07.25715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(dt):    \n    #data = np.genfromtxt(dt, delimiter=',', skip_header=1)#[:,-2]\n    #data = data[:,-3]\n    \n    mu_list = []\n    sigma_list = []\n    pi_list = []\n    \n    for i in range(17):\n        \n        data = dt[:,i]\n        N = dt.shape[0]\n        K = 4 # two components GMM\n        tot_iterations = 100 # stopping criteria\n\n        # Step-1 (Init)\n        mu_high = np.mean(data) + np.std(data)\n        mu_low = np.mean(data) - np.std(data)\n\n        sigma_high = np.var(data) + np.std(data)  \n        sigma_low =  np.var(data) - np.std(data) \n\n        mu = np.random.uniform(low = mu_low, high = mu_high, size=K) # mean\n        sigma = np.random.uniform(low = sigma_low, high = sigma_high, size=K) # standard deviaiton\n\n        #mu = np.random.uniform(low=42.0, high=95.0, size=K)\n        #sigma = np.random.uniform(low=5.0, high=10.0, size=K)\n\n        pi = np.ones(K) * (1.0/K) # mixing coefficients\n        r = np.zeros([K,N]) # responsibilities\n        nll_list = list() # store the neg log-likelihood\n\n        for iteration in range(tot_iterations):  \n            # Step-2 (E-Step)\n            for k in range(K):\n                r[k,:] = pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n            r = r / np.sum(r, axis=0) #[K,N] -> [N]\n\n            # Step-3 (M-Step)\n            N_k = np.sum(r, axis=1) #[K,N] -> [K]\n            for k in range(K): \n                # update means\n                mu[k] = np.sum(r[k,:] * data) / N_k[k]        \n                # update variances\n                numerator = r[k] * (data - mu[k])**2\n                sigma[k] = np.sqrt(np.sum(numerator) / N_k[k])        \n            # update weights\n            pi = N_k/N \n\n            likelihood = 0.0\n            for k in range(K):\n                likelihood += pi[k] * norm.pdf(x=data, loc=mu[k], scale=sigma[k])\n            nll_list.append(-np.sum(np.log(likelihood)))        \n            # Check for invalid negative log-likelihood (NLL)\n            # The NLL is invalid if NLL_t-1 < NLL_t\n            # Note that this can happen for round-off errors.\n            if(len(nll_list)>=2):\n                if(nll_list[-2]<nll_list[-1]): raise Exception(\"[ERROR] invalid NLL: \"+str(nll_list[-2:]))\n\n            #print(\"Iteration: \" + str(iteration) + \"; NLL: \" + str(nll_list[-1]))\n            #print(\"Mean \" + str(mu) + \"\\nStd \" + str(sigma) + \"\\nWeights \" + str(pi) + \"\\n\")     \n\n            # Step-4 (Check)\n            if(iteration == tot_iterations-1): break # check iteration\n        \n        if min(mu) > 0: mu_list.append(mu)\n        if min(sigma) > 0: sigma_list.append(sigma)\n        if min(pi) > 0: pi_list.append(pi)\n        \n    return (mu_list, sigma_list, pi_list)\n    \n    #plot_likelihood(nll_list)\n    #data_gmm = sampler(pi, mu, sigma, N=1000)\n    #plot_distributions(data, data_gmm, mu, sigma, K, color=\"green\", color_sampled=\"red\", name=\"plot_sampler.png\")","metadata":{"execution":{"iopub.status.busy":"2021-07-06T17:35:57.148387Z","iopub.execute_input":"2021-07-06T17:35:57.148738Z","iopub.status.idle":"2021-07-06T17:35:57.165678Z","shell.execute_reply.started":"2021-07-06T17:35:57.148707Z","shell.execute_reply":"2021-07-06T17:35:57.164526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = main(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T17:35:58.011129Z","iopub.execute_input":"2021-07-06T17:35:58.011499Z","iopub.status.idle":"2021-07-06T17:36:02.062295Z","shell.execute_reply.started":"2021-07-06T17:35:58.011467Z","shell.execute_reply":"2021-07-06T17:36:02.061161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(a[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T17:37:29.524236Z","iopub.execute_input":"2021-07-06T17:37:29.524569Z","iopub.status.idle":"2021-07-06T17:37:29.529622Z","shell.execute_reply.started":"2021-07-06T17:37:29.524539Z","shell.execute_reply":"2021-07-06T17:37:29.52894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_likelihood(nll_list):\n    #matplotlib.rcParams['text.usetex'] = True\n    #plt.rcParams.update({'font.size': 16})\n    \n    plt.plot(np.arange(len(nll_list)), nll_list, color=\"black\", linestyle=\"--\", linewidth=3)\n    plt.ylabel(r\"(negative) log-likelihood\")\n    plt.xlabel(r\"iteration\")\n    plt.tight_layout()\n    plt.xlim(0, len(nll_list))\n    plt.savefig('real_dataset_normal_ll.png', dpi=200)\n    #plt.savefig('./gmm_film{}.png'.format(num))\n    #plt.clf()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:38:13.12549Z","iopub.execute_input":"2021-07-06T14:38:13.125855Z","iopub.status.idle":"2021-07-06T14:38:13.132218Z","shell.execute_reply.started":"2021-07-06T14:38:13.125823Z","shell.execute_reply":"2021-07-06T14:38:13.131039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_likelihood(a)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:38:13.406147Z","iopub.execute_input":"2021-07-06T14:38:13.406505Z","iopub.status.idle":"2021-07-06T14:38:13.755381Z","shell.execute_reply.started":"2021-07-06T14:38:13.406474Z","shell.execute_reply":"2021-07-06T14:38:13.754264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}